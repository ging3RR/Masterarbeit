---
output: html_document
bibliography: "references.bib"
fontsize: 12pt
geometry: margin = 1.2in 
---
<style> body {text-align: justify} </style> <!-- https://stackoverflow.com/questions/58713332/justify-text-in-rmarkdown-html-output-in-yaml-header -->
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Kapitel 3

In diesem Kapitel folgt die Beschreibung des empirischen Materials sowie der verwendeten Methoden für die Analyse der Daten. In dieser Arbeit wird eine soziologische Sichtweise auf die Frage der Arbeitszeitverkürzung geworfen. Dabei steht die Diskussion um die Arbeitsverkürzung und speziell die erste und einzige gesamtschweizerische Rechtsgebung mit dem Arbeitsgesetz von 1964 im Fokus. Die Daten werden Mithilfe von Computergestützer Textanalyse bearbeitet. Somit befindet sich diese Arbeit zwischen Bereichen der Sozialwissenschaften, sowie Datenwissenschaften. Es wird also nebst der soziologischen Behandlung des Themas auch einen stärkeren Fokus auf die technischen Teil der Methoden eingegangen. Anschliessend an die Beschreibung des technischen Teils wird auf die (soziologische) Methoden und Vorgehensweise eingegangen.

## Technische Vorbermerkung

Ein wichtiger Aspekt für Forschung ist die Reproduzierbarkeit von Forschungsergebnissen. Erst durch die Reproduzierbarkeit können Ergebnisse nachgeprüft und von der Forschungsgesellschaft verifiziert werden. Einer der Grundpfeiler vieler Journals ist das sogenannte Peer-Reviewing. Es ist somit von grösster Wichtigkeit Forschungsarbeiten so zu verfassen, dass die Ergebnisse nicht nur nachvollziehbar, sondern eben auch reproduzierbar sind. Mit dem immer grösseren Zufluss von computergestützten Methoden in den Sozialwissenschaften erhält dieses Thema noch mehr Gewicht. Viele Algorithmen verwenden unsupervised oder semi-supervised Methoden und werden darum auch oft "Blackboxes" genannt. Doch auch wenn nicht immer ganz durchsichtig, können Vorkehrungen getroffen werden, um die Forschungsarbeiten und Ergebnisse zu reproduzieren. Für die Analyse in dieser Arbeit wurden einige solche Vorkehrungen getroffen. Ein wichtiger Punkt für die Reproduzierbarkeit ist die Transparenz der Methoden, aus diesem Grund wurde der ganze Code und Text in einem Github Repository veröffentlicht. Einzig die Daten dürfen nicht veröffentlicht werden, da dieser unter Copyright stehen. Im Teil weiter unten wird jedoch erklärt wo die Daten zur Verfügung stehen. Sobald die Daten zur Verfügung stehen, können jedoch alle Scripts und Methoden genau gleich angewandt werden. Des weiteren wird das Github Repository mit einer Docker Version zu Verfügung gestellt. Damit kann die virtuelle Umgebung in der gearbeitet wird nachgebaut werden. Dies verhindert unter anderem auch Fehler durch unterschiedliche Versionen von Softwares. 

Die ganze Arbeit wurde in RStudio geschrieben. Die Texte sind in RMarkdown geschrieben und werden mithilfe von `Bookdown`zu einem PDF Output zusammengefügt. Die Scripte für die Analyse sind zum grössten Teil in der R Programmiersprache geschrieben. Eines der Data Cleaning Scripts wurde in Python geschrieben, da eines der Probleme nicht in R gelöst werden konnte. Auch dieses Python Script ist innerhalb der RStudio Umgebung mithilfe des `reticulate` Packages ausführbar. Es ist möglich, die Analysen im vierten Teil dieser Arbeit nachrechnen zu lassen und allenfalls andere Parameter zu wählen, um bessere Forschungsergebnisse zu erhalten. Für diese Analyse wurde unter anderem das `LDA Prototype`Package von Rieger et al. verwendet[@riegerImprovingReliabilityLatent2020; @riegerLdaPrototypeMethodGet2020]. Dieses Package sorgt für bessere Reproduzierbarkeit bei LDA Analysen von Texten. 

**HIER AUF DIE LDA METHODEN EINGEHEN**


## Daten

Bevor genauer auf die Methoden eingegangen wird folgt hier noch eine Beschreibung der Daten, die für die Analysen genutzt worden sind. Wie im theoretischen Teil bereits angesprochen sind der Schweizerische Gewerkschaftsbund (SGB) und der Zentralverband schweizerischer Arbeitgeber-Organisationen (ZSAO) zwei der wichtigsten Verhandlungsteilnehmer rund um die Arbeitszeitdiskussion. Es war möglich für beide dieser Verbände den gesamten Bestand der Mitgliederzeitungen von 1930 bis 1970 zu erhalten. <br>
Die Mitgliederzeitung des SGB heisst Gewerkschaftliche Rundschau und ist in den Jahren ... bis ... im Vierteljahrestakt und in den Jahren ... bis ... im Monatstakt herausgegeben worden. **MEHR INFOS ZUR ZEITUNG** Die digitalen Scans der Gewerkschaftlichen Rundschau sind auf dem E-Periodica Archiv der ETH Zürich öffentlich zugänglich. Für diese Arbeit hat der Autor die digitalisierten Texte im .txt Format erhalten. <br>
Die Zeitung des ZSAO ist jährlich erschienen und trägt den Namen Arbeitsgeber.**MEHR INFOS ZUR ZEITUNG** Die Zeitschriften sind vor Kurzem auch an das Archiv der ETHZ übergeben worden. Sie sind jedoch nicht öffentlich zugänglich. Eine digitalisierte Version der Zeitschriften konnte das Wirtschaftsarchiv der Universität Basel zu Verfügung stellen. Diese Texte waren im OCR Verfahren der Firma ... eingelesen worden. Als Output dieses Verfahrens entstehen XML Dateien. Wie bereits angesprochen mussten für das Einlesen dieser Texte in RStudio ein Python Script verwendet werden. Der Grund dafür war die Struktur des XML, in dem der Textinhalt in einer verschachtelten Child Node zu finden war. In der R Sprache konnte dieses Problem leider nicht gelöst werden, da der gewünschte Synthax nicht herausgefunden werden konnte. Da dieses Problem einfacher in Python gelöst werden konnte, wurde schlussendlich zu dieser weniger eleganten Lösung zurückgegriffen. 

**ZUSAMMENFASSENDE INFORMATIONEN ZU DEN TEXTEN** 

Da das Thema dieser Arbeit der Diskurs um die Arbeitszeitverkürzung ist, war es sinnvoll das empirische Material vorzusortieren. In den Zeitungen werden viele verschiedene Themen angeschnitten und diskutiert. Daher wurden die Texte so vorsotiert, dass nur Texte mit dem Wort Arbeitszeit in die zwei Analyse-Korpora integriert worden sind. Für diese Auswahl wurde eine *Keywords in context* (KWIC) Analyse mit dem Schlagwort "Arbeitszeit" durchgeführt. Die KWIC Analyse wurde mithilfe des `quanteda` Packages durchgeführt. Bei dieser Analyse werden die Texte nach dem gewünschten Wort durchsucht. Als Ausgabe wird das Wort und einige Wörter vor und nach dem Wort ausgegeben. In diesem Moment war der Kontext des Wortes Arbeitszeit aber noch eher unwichtig. Zusätzlich wird in der Ausgabe noch die ID des Textes angegeben. Diese ID's wurden zu einer Liste zusammengefasst und mit dieser Liste wurden dann alle Texte aussortiert. Schlussendlich blieben bei beiden Korpora nur noch Texte übrig in denen mindestens einmal das Wort Arbeitszeit vorkommt. 

**HIER INFOS ZU DIMENSIONEN DER AUSSORTIERTEN KORPORA** 