# Methoden

Nach der theoretischen Behandlung des Themas im vorherigen Kapitel, wird in diesem Kapitel das empirischen Material, sowie die verwendeten Methoden für die Analyse der Daten beschrieben. Im Fokus steht die Diskussion um die Arbeitsverkürzung im Zeitraum der ersten und einzigen gesamtschweizerische Rechtsgebung: dem Arbeitsgesetzt von 1964. Als Grundlage für die Auswertungen werden die Mitgliederzeitschriften der beiden Verbände SGB und ZSAO verwendet. Die zwei Verbände sind als Ordnungskräfte massgeblich an der politischen Debatte, sowie an der rechtliche Umsetzung von Arbeitszeitregulierungen beteiligt. Die Zeitschriften werden mithilfe von computergestützer Textanalyse bearbeitet. Ein wichtiger Aspekt für wissenschaftliche Forschung ist die Reproduzierbarkeit von Forschungsergebnissen. Erst durch die Reproduzierbarkeit können Ergebnisse nachgeprüft und von der Forschungsgesellschaft verifiziert werden. Nicht ohne Grund ist einer der Grundpfeiler vieler Journals das sogenannte Peer-Reviewing. Es ist somit von grösster Wichtigkeit Forschungsarbeiten so zu verfassen, dass die Ergebnisse nicht nur nachvollziehbar, sondern eben auch reproduzierbar sind [@bakerWhyScientistMust2016; @granellReproducibleResearchRiding2018; @peelsPossibilityDesirabilityReplication2018]. Mit der immer grösseren Ausbreitung von computergestützten Methoden in den Sozialwissenschaften erhält dieses Thema noch mehr Gewicht. Viele Algorithmen verwenden unsupervised oder semi-supervised Methoden und werden darum auch oft "Blackboxes" genannt [für ein Erklärung solcher Algorithmen siehe @oneilDoingDataScience2013]. Doch auch wenn nicht immer ganz durchsichtig, können Vorkehrungen getroffen werden, um die Forschungsarbeiten und Ergebnisse zu reproduzieren. Für die Analyse in dieser Arbeit wurden einige solche Vorkehrungen getroffen. Ein wichtiger Punkt für die Reproduzierbarkeit ist die Transparenz der Methoden, aus diesem Grund wurde der ganze Code und Text in einem Github Repository veröffentlicht. Einzig die Daten dürfen nicht veröffentlicht werden, da diese unter Copyright stehen. Im Teil weiter unten wird jedoch erklärt wo die Daten zur Verfügung stehen. Sobald die Daten zur Verfügung stehen, können alle Scripts und Methoden genau gleich angewandt werden. Des Weiteren wird das Github Repository mit einer Docker Version zu Verfügung gestellt. Damit kann die virtuelle Umgebung, in der gearbeitet wird, nachgebaut werden. Dies verhindert unter anderem auch Fehler durch unterschiedliche Versionen von Softwares. 

Die ganze Arbeit wurde in RStudio verfasst und programmiert. Die Texte sind in RMarkdown geschrieben und werden mithilfe von `Bookdown` zu einem PDF Output zusammengefügt. Der Workflow für die Arbeit und das Github Repository stammt von Thea Knowles [@knowlesDissertatingRMarkdownBookdown2019] in Anlehnung an Lucy D'Agostino McGowan [@dagostinomcgowanOneYearDissertate2018]. Ein weiteres wichtiges Mittel für die Arbeit mit Bookdown in RStudio stammt aus der Dokumenation von Bookdown geschrieben von Yihui Xie, der das Package auch entwickelt hat [@xieBookdownAuthoringBooks2022]. Die Scripte für die Analyse sind zum grössten Teil in der R Programmiersprache geschrieben. Eines der Data Cleaning Scripts wurde in Python geschrieben, da ein Probleme nicht in R gelöst werden konnte. Auch dieses Python Script ist innerhalb der RStudio Umgebung mithilfe des `reticulate` Packages ausführbar [@R-reticulate]. Ein grosser Vorteil dieses Workflows ist die einfache Anpassung der Analysen. Es ist möglich, die Analysen im vierten Teil dieser Arbeit nachrechnen zu lassen und allenfalls andere Parameter zu wählen, um bessere Forschungsergebnisse zu erhalten. Somit können immer wieder neue Erkenntnisse in die Analysen miteinbezogen werden, ohne noch einmal alles von Grund auf programmieren zu müssen. Ausserdem können dieselben Verfahren für anderes empirisches Material genützt werden. Dies ermöglicht wiederum verschieden Materialien zu vergleichen und die Methoden auf ihre Generalisierbarkeit zu überprüfen.

## Daten

Bevor genauer auf die Methoden eingegangen wird folgt hier eine Beschreibung der Daten, die für die Analysen genutzt worden sind. Wie im theoretischen Teil bereits angesprochen sind der Schweizerische Gewerkschaftsbund (SGB) und der Zentralverband schweizerischer Arbeitgeber-Organisationen (ZSAO) zwei der wichtigsten Verhandlungsteilnehmer rund um die Arbeitszeitdiskussion. Es war möglich für beide dieser Verbände den gesamten Bestand der Mitgliederzeitungen von 1930 bis 1970 zu erhalten. Der Erwerb der Zeitschriften war zu seiner Zeit kostenpflichtig. Dies zeigt, dass die Zeitschriften vor allem an aktive und interessierte Mitglieder gerichtet war. Es unterscheidet sich somit von einem Flugblatt oder politischen Abstimmungswerkzeugen wie z.B. Plakaten. <br>
Die Mitgliederzeitung des SGB heisst *Gewerkschaftliche Rundschau* und wurde im Untersuchungszeitraum monatlich herausgegeben. Erst ab den 80er Jahren wurde die Rundschau dann zweimonatlich und schlussendlich vierteljährlich veröffentlicht. Die digitalen Scans der Gewerkschaftlichen Rundschau sind auf dem E-Periodica Archiv der ETH Zürich öffentlich zugänglich. Die einzelnen Ausgaben, auch Hefte genannt, werden in Bänden pro Jahr zusammengefasst. Für diese Arbeit hat der Autor die digitalisierten Texte im .txt Format direkt vom Archiv erhalten. <br>
Die Zeitung des ZSAO ist jährlich erschienen und trägt den Namen *Schweizer Arbeitgeber*. Die Zeitschriften sind vor Kurzem auch an das Archiv der ETH Zürich übergeben worden. Sie sind jedoch nicht öffentlich zugänglich. Eine digitalisierte Version der Zeitschriften konnte das Wirtschaftsarchiv der Universität Basel zu Verfügung stellen. Diese Texte wurden mit einem OCR Verfahren mithilfe der Tesseract Software verarbeitet. Als Output dieses Verfahrens entstehen XML Dateien. 

Die beiden Korpora sind von unterschiedlicher Grösse. Die *Gewerkschaftliche Rundschau* wurde in den Jahren 1930 - 1970 rund 480 Mal herausgegeben. Die Zeitschrift *Schweizer Arbeitgeber* wurde jeweils einmal pro Jahr veröffentlicht. Somit gibt es 40 Ausgaben dieser Zeitschrift. Bei beiden Korpora entspricht eine Datei (txt oder XML) jeweils einer Seite des Hefts. Für die *Gewerkschaftliche Rundschau* sind für die Jahre 1930 - 1970 insgesamt rund 18'000 Dateien vorhanden. Dies entsprich 450 Seiten pro Jahr oder 37.5 Seiten pro Monat. Beim *Schweizer Arbeitgeber* sind es insgesamt rund 59'000 Dateien. Also 1'475 Seiten pro Jahr und ca. 123 Seiten pro Monat. Der Korpus des ZSAO ist somit rund dreimal grösser als der des SGB.

Da das Thema dieser Arbeit der Diskurs um die Arbeitszeitverkürzung ist, war es sinnvoll das empirische Material vorzusortieren. In den Zeitungen werden viele verschiedene Themen angeschnitten und diskutiert. Daher wurden die Texte so vorsortiert, dass nur Texte mit dem Wort Arbeitszeit in die zwei Analyse-Korpora integriert worden sind. Für diese Auswahl wurde eine *Keywords in context* (KWIC) Analyse mit dem Schlagwort "Arbeitszeit" durchgeführt. Die KWIC Analyse wurde mithilfe des `quanteda` Packages durchgeführt [@benoitQuantedaPackageQuantitative2018]. Bei dieser Analyse werden die Texte nach dem gewünschten Wort durchsucht. Als Ausgabe wird das Wort und einige Wörter vor und nach dem Wort ausgegeben. In diesem Moment war der Kontext des Wortes Arbeitszeit aber noch eher unwichtig. Zusätzlich wird in der Ausgabe noch die ID des Textes angegeben. Diese ID's wurden zu einer Liste zusammengefasst und mit dieser Liste wurden dann alle Texte aussortiert. Schlussendlich blieben bei beiden Korpora nur noch Texte übrig in denen mindestens einmal das Wort Arbeitszeit vorkommt. ^[Auf dem Github Repository dieser Arbeit sind die Scripte für die Auswahl unter /scripts zu finden. Für die *Gewerkschaftliche Rundschau* wurde das Script *Aussortieren* benutzt. Beim *Schweizer Arbeitgeber* ist das Aussortieren im ersten Teil des *Arbeitgeber_2* Script.]

Nach dem Aussortieren blieben beim Korpus des SGB noch 1027 (5.7%) Dateien übrig. Beim Korpus des ZSAO noch 2217 (3.7%) Dateien. In beiden Korpora sind aus jedem Jahr mindestens ein Text vorhanden. Das Wort Arbeitszeit wurde somit mindestens einmal pro Jahr in den Zeitschriften erwähnt. Die Grösse der Dateien ist in den beiden Korpora unterschiedlich. Durchschnittlich hat eine Datei der *Gewerkschaftlichen Rundschau* 365 Tokens. Der Durchschnitt beim *Schweizer Arbeitgeber* ist rund 1100 Tokens. Der Korpus des ZSAO bleibt somit um einiges grösser als der des SGB.
Bei der Umwandlung in ein Korpus Objekt werden die verschiedene Zeichen und Wörter aus den Texten entfernt. Was genau entfernt wird kann jeweils mit Parametern angegeben werden. Bei beiden Korpora wurden Sonderzeichen und eine Liste von deutschen und französischen Stopwörtern entfernt. Dafür wird eine Liste von Stopwörtern (oft verwendete Wörter ohne interpretierbaren Inhalt wie z.B. Konjunktionen oder Artikel) aus dem `Stopwords Package` aus den Texten entfernt [@muhrStopwordsPackage2021]. ^[Stopwörter müssen nicht immer entfernt werden. Je nach Analyse ist es sogar nötig die Stopwörter nicht zu entfernen. Zum Beispiel bei der Identifizierung von Autor:innen in denen die Verhältnisse von bestimmten Wortgruppen miteinander verglichen werden [@raghunadhareddyNewDocumentRepresentation2019; @reddy2016survey]. Für die explorative Untersuchung von Dimension in Texten sind Stopwörter aber störend, da sie keine Interpretation zu den Themen in den Texten zulassen.] Zusätzlich wurden nach qualitativer Analyse der Texte und Auswertungen weitere störende Wörter entfernt. Eine genaue Übersicht über die Stopwörter findet sich im Script *stopwords.R*. 


## Analyseverfahren

Die *Latent dirichlet allocation* (LDA) ist eine Textanalyse Methode, die dazu dient die Dimensionen eines Korpus zu verringern [@10.5555/944919.944937]. In dieser Methoden werden alle Wörter in unterschiedliche Wortlisten eingeteilt. In diesen Wortliste, auch Topics genannt, werden die Wörter aufgrund eines Wahrscheinlichkeitswertes sortiert. Die Topwörter mit den höchsten Werten sollten idealerweise ein menschlich interpretierbares Thema innerhalb des Korpus repräsentieren. Die Anzahl der Topics kann vor der Analyse vorgegeben werden. Die Anzahl soll dabei so gewählt werden, dass nicht alle Themen der Texte in den Wortlisten vorkommen. Das Ziel soll eine Reduktion der Dimension bleiben. Dennoch müssen es genügend Topics sein, um als Grundlage für eine Analyse des Forschunggegenstands dienen zu können [@vonnordheimYoungFreeBiased2019a]. Die Anzahl der Topics wird durch die Themen und die Komplexität des Korpus vorgegeben [@10.1145/2597008.2597150]. Da die Topics menschlich interpretierbar sein sollen, spielt auch die Vertrautheit mit dem empirischen Material eine wichtige Rolle, da sonst allfällige wichtige Wörter nicht erkannt werden. Weil in der Bestimmung der Wahrscheinlichkeiten der erste Schritt zufällig ist, kann das LDA Verfahren oft verschiedene Resultate ergeben. Um dies zu verhindern werden beim `LDA Prototype` Package mehrere Durchgängen gemacht. Von all diesen Durchgängen wird schlussendlich ein LDA Durchgang mit der grössten Ähnlichkeit zu allen anderen bestimmt. Diesen LDA Durchgang nennen Rieger et al. den Prototype. Diese Methode dient zur Absicherung und besseren Reproduzierbarkeit eines LDA Ergebnisses [@riegerImprovingReliabilityLatent2020; @riegerLdaPrototypeMethodGet2020]. Die Autor:innen empfehlen mindestens 50 Durchgänge ausrechnen zu lassen und dies je nach Komplexität der Korpora zu erhöhen.^[Eine genaue technische Ausführung zu den LDA Methoden findet sich in den zitierten Texten von Blei et al. und Rieger et al.] Da es keine objektiven Kriterien zur Festlegung der Anzahl Topics gibt, ist die Überprüfung der Validität der Ergebnisse extrem wichtig. Eine Möglichkeit ist zu schauen, ob die Topics auch intersubjektiv nachvollziehbar sind und ob die Topics einigermassen konsistent sind. Das `Tosca` Package [@jonas_rieger_2020_3703066] erlaubt eine solche Validitätsprüfung mit der Funktion `intruderwords`. Dabei wird ein Konzept von Chang et al. verwendet, dass sich *"reading tealeaves"* nennt [@10.5555/2984093.2984126]. Die Idee ist eine Auswahl aus Wörtern aus einem bestimmten Topic zu zeigen. Unter dieser Auswahl verstecken sich auch (ein oder mehrere) Wörter, die nicht in diesem Topic zu finden sind. Diese Wörter sind die sogenannten *Intruderwords*. Bei einem gut abgrenzbaren Topic sollte es möglich sein, die Intruderwords zu erkennen. Ist das Topic schlecht abgrenzbar, kann nicht unterschieden werden, welche Wörter wirklich zum Topic gehören und welche nicht. Bei der Funktion aus dem Tosca Package können einige Parameter angegeben werden. Es werden pro Durchgang jeweils 5 Wörter angezeigt. Die Anzahl der Intruder wurde auf ein Wort angesetzt. Weiter kann festgelegt werden, wie viele der Topwords genützt werden sollen. Hier wurde der Parameter auf zehn Topwords eingestellt. Die Interpretation der Topics erfolgte jeweils mithilfe dieser zehn Topwords. Daher macht es auch Sinn die Validität mit den zehn Topwords zu überprüfen. Ein Durchgang umfasst jeweils soviele Stichproben, wie es Topics gibt. Es gibt jedoch die Möglichkeit ein nicht interpretierbares Topic zu kennzeichnen. Wird dies als solches gekennzeichnet gibt es eine zusätzliche Stichprobe. Ein Durchgang kann also je nachdem auch mehr Stichproben als die Anzahl Topics haben.
Durchgeführt wurde die Validitätsprüfung von drei verschiedenen Personen. Eine Person war der Autor dieser Arbeit. Die anderen zwei Personen haben sich nicht mit diesem Thema oder der Arbeit auseinandergesetzt. Die Idee dabei ist, dass vom Autor der Kontext und das Thema verstanden wird und somit die Überprüfung einfach funktionieren sollte. Dies sollte zeigen, dass mit genügend Wissen die Topics gut voneinander abgrenzbar sind. Die Überprüfung der anderen zwei Personen sollte genau das Gegenteil untersuchen. Ist es auch möglich ohne Vorwissen die Topics voneinander abzugrenzen? Für die Validitätsprüfung wurden jeweils drei Durchgänge pro Person durchgeführt. 

Eine weitere verwendete Analyse Methode ist die Sentiment Analyse mithilfe eines Wörterbuchs. Wie politischen Organisationen über bestimmte Themen reden, ist eine wichtige Informationsquelle zur Interpretation des Themas [@rauhValidatingSentimentDictionary2018, S.319]. Die Sentiment Analyse wird in unterschiedlichen Forschungsdisziplinen angewendet [z.B. Sportwissenschaften @app10020431; oder Gesundheitswissenschaften @yangModellingClinicalExperience2020]. Bei der Sentiment Analyse werden alle Wörter in eine positive oder negative Kategorie eingeteilt. ^[Einige Wörterbücher verwenden auch eine dritte Kategorie für neutrale Wörter. Siehe dafür zum Beispiel das Lexicoder Sentiment Dictionary[@youngAffectiveNewsAutomated2012]] Dies geschieht mithilfe des Wörterbuchs, in dem viele Wörter zusammen mit einem positiven oder negative Wert eingetragen sind. Die Wörter aus den Texten werden mit dem Wörterbuch gematcht und der Wert wird übertragen. Anschliessend lässt sich durch das Aufsummieren und Zusammenfassen sagen, ob der Text/Korpus insgesamt eher negativ oder positiv ist. In dieser Arbeit wird dafür ein deutsches Wörterbuch von Christian Rauh [@rauhValidatingSentimentDictionary2018] verwendet, das auf Grundlage des SentiWS Wörterbuchs der Universität Leipzig gebaut wurde [@goldhahn-etal-2012-building]. Für die deutsche Sprache gibt es fast keine anderen Wörterbücher als das SentiWS und das Wörterbuch von Rauh. Daher ist die Validität dieser Wörterbücher extrem wichtig. Das Wörterbuch von Rauh fokussiert sich glücklicherweise auf politische Kommunikation. Wie bereits besprochen kann die Kommunikation in den Zeitschriften der Gewerkschaften und Arbeitgeber:innenverbänden als politische Kommunikation kategorisiert werden. Die Validität für dieses Wörterbuch ist im Forschungskontext dieser Arbeit somit besser gegeben, als wenn es sich um nicht-politische Kommunikation handeln würde. Das Ziel der Sentiment Analyse ist herauszufinden, ob die Gewerkschaften und die Arbeitgeber-Organisationen positiv oder negativ über das Thema Arbeitszeit kommunizieren.
