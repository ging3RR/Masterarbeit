@Article{amooreDataDerivativesEmergence2011,
  title = {Data {{Derivatives}}: {{On}} the {{Emergence}} of a {{Security Risk Calculus}} for {{Our Times}}},
  shorttitle = {Data {{Derivatives}}},
  author = {Louise Amoore},
  date = {2011-11-01},
  journaltitle = {Theory, Culture \& Society},
  shortjournal = {Theory, Culture \& Society},
  volume = {28},
  number = {6},
  pages = {24--43},
  publisher = {{SAGE Publications Ltd}},
  issn = {0263-2764},
  doi = {10.1177/0263276411417430},
  url = {https://doi.org/10.1177/0263276411417430},
  urldate = {2021-12-28},
  abstract = {In a quiet London office, a software designer muses on the algorithms that will make possible the risk flags to be visualized on the screens of border guards from Heathrow to St Pancras International. There is, he says, ‘real time decision making’ – to detain, to deport, to secondarily question or search – but there is also the ‘offline team who run the analytics and work out the best set of rules’. Writing the code that will decide the association rules between items of data, prosaic and mundane – flight route, payment type, passport – the analysts derive a novel preemptive security measure. This paper proposes the analytic of the data derivative – a visualized risk flag or score drawn from an amalgam of disaggregated fragments of data, inferred from across the gaps between data and projected onto an array of uncertain futures. In contrast to disciplinary and enclosed techniques of collecting data to govern population, the data derivative functions via ‘differential curves of normality’, imagining a range of potential futures through the association rule, thus ‘opening up to let things happen’ (Foucault 2007). In some senses akin to the risk orientation of the financial derivative, itself indifferent to actual underlying people, places or events by virtue of modulated norms, the contemporary security derivative is not centred on who we are, nor even on what our data say about us, but on what can be imagined and inferred about who we might be – on our very proclivities and potentialities.},
  langid = {english},
  keywords = {borderzones,risk,security,technology},
  file = {C\:\\Users\\lukas\\Zotero\\storage\\4HELGX29\\Amoore - 2011 - Data Derivatives On the Emergence of a Security R.pdf},
}

@techreport{baderWenigerIstMehr2020,
  type = {{{CDE Working Papers}}},
  title = {Weniger Ist {{Mehr}} - {{Der}} Dreifache {{Gewinn}} Einer {{Reduktion}} Der {{Erwerbsarbeitszeit}}. {{Weniger}} Arbeiten Als {{Transformationsstrategie}} F\"ur Eine \"Okologischere, Gerechtere Und Zufriedenere {{Gesellschaft}} - {{Implikationen}} F\"ur Die {{Schweiz}}},
  author = {Bader, Christoph and Hanbury, Hugo and Neubert, Sebastian and Moser, Stephanie},
  year = {2020},
  number = {6},
  address = {{Bern}},
  institution = {{Centre for Development and Environment (CDE)}}
}
@Misc{kaufmannVierzigstundenwocheSchweizAnschaulichtheoretischer1960,
  title = {Vierzigstundenwoche in der Schweiz? : ein anschaulich-theoretischer Beitrag zur Geschichte und zur Problematik der Arbeitszeitsverkürzung in der Schweiz},
  author = {Peter Kaufmann},
  date = {1960},
  journaltitle = {Vierzigstundenwoche in der Schweiz? ein anschaulich-theoretischer Beitrag zur Geschichte und zur Problematik der Arbeitszeitsverkürzung in der Schweiz},
  series = {Staatswissenschaftliche Studien. Neue Folge Bd. 41},
  publisher = {{Polygr. Verl.}},
  location = {{Zürich}},
  langid = {german},
  keywords = {Arbeitszeit},
}
@Misc{alma99312190105505,
  title = {Ökonomische, rechtliche und verbandspolitische Fragen in der Auseinandersetzung um die Arbeitszeit während der Hochkonjunktur (1946-1975) in der Schweiz und in Österreich},
  author = {Werner W{\"u}thrich},
  date = {1987},
  publisher = {{Rüegger}},
  location = {{Grüsch}},
  isbn = {3725302944},
  langid = {german},
  keywords = {1946-1975},
}
@Unpublished{riegerImprovingReliabilityLatent2020,
  title = {Improving {{Reliability}} of {{Latent Dirichlet Allocation}} by {{Assessing Its Stability Using Clustering Techniques}} on {{Replicated Runs}}},
  author = {Jonas Rieger and Lars Koppers and Carsten Jentsch and J{\"o}rg Rahnenf{\"u}hrer},
  date = {2020-02-14},
  eprint = {2003.04980},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  doi = {10.48550/arXiv.2003.04980},
  url = {http://arxiv.org/abs/2003.04980},
  urldate = {2022-05-12},
  abstract = {For organizing large text corpora topic modeling provides useful tools. A widely used method is Latent Dirichlet Allocation (LDA), a generative probabilistic model which models single texts in a collection of texts as mixtures of latent topics. The assignments of words to topics rely on initial values such that generally the outcome of LDA is not fully reproducible. In addition, the reassignment via Gibbs Sampling is based on conditional distributions, leading to different results in replicated runs on the same text data. This fact is often neglected in everyday practice. We aim to improve the reliability of LDA results. Therefore, we study the stability of LDA by comparing assignments from replicated runs. We propose to quantify the similarity of two generated topics by a modified Jaccard coefficient. Using such similarities, topics can be clustered. A new pruning algorithm for hierarchical clustering results based on the idea that two LDA runs create pairs of similar topics is proposed. This approach leads to the new measure S-CLOP (\{\textbackslash bf S\}imilarity of multiple sets by \{\textbackslash bf C\}lustering with \{\textbackslash bf LO\}cal \{\textbackslash bf P\}runing) for quantifying the stability of LDA models. We discuss some characteristics of this measure and illustrate it with an application to real data consisting of newspaper articles from \textbackslash textit\{USA Today\}. Our results show that the measure S-CLOP is useful for assessing the stability of LDA models or any other topic modeling procedure that characterize its topics by word distributions. Based on the newly proposed measure for LDA stability, we propose a method to increase the reliability and hence to improve the reproducibility of empirical findings based on topic modeling. This increase in reliability is obtained by running the LDA several times and taking as prototype the most representative run, that is the LDA run with highest average similarity to all other runs.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\lukas\\Zotero\\storage\\4E8AU4KK\\Rieger et al. - 2020 - Improving Reliability of Latent Dirichlet Allocati.pdf;C\:\\Users\\lukas\\Zotero\\storage\\5ZRJ5PQN\\2003.html},
}

@Article{riegerLdaPrototypeMethodGet2020,
  title = {{{ldaPrototype}}: {{A}} Method in {{R}} to Get a {{Prototype}} of Multiple {{Latent Dirichlet Allocations}}},
  author = {Jonas Rieger},
  date = {2020},
  journaltitle = {Journal of Open Source Software},
  volume = {5},
  number = {51},
  pages = {2181},
  doi = {10.21105/joss.02181},
  url = {https://doi.org/10.21105/joss.02181},
}
